{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework CAPITA SELECTA PU Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, mean_squared_error as mse\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def ignore_warnings():\n",
    "    import warnings\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "ignore_warnings()\n",
    "\n",
    "#from PU_Learning import *\n",
    "from PU_Learning import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset1_train.csv')\n",
    "X1_train= data.iloc[:, :-2].values\n",
    "y1_train = data.iloc[:, -1].values\n",
    "s1 = data.iloc[:, -2].values\n",
    "c1 = Counter(s1)[1]/Counter(y1_train)[1]\n",
    "\n",
    "data = pd.read_csv('Dataset1_test.csv')\n",
    "X1_test= data.iloc[:, :-1].values\n",
    "y1_test = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 180, 0: 232})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golden Standard Classifier (first dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden Standard Classifier: F1 score: 0.9917355371900827\n"
     ]
    }
   ],
   "source": [
    "# Consider the dataset as fully labeled. Use this as the best case in the comparison.\n",
    "\n",
    "golden_clf = svm.SVC(kernel='rbf',probability=True,random_state = 331).fit(np.copy(X1_train),np.copy(y1_train))\n",
    "name = \"Golden Standard Classifier:\"\n",
    "\n",
    "y_best_pred = golden_clf.predict(np.copy(X1_test))\n",
    "y_best_prob = golden_clf.predict_proba(np.copy(X1_test))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Traditional Classifier (first dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Traditional Classifier F1 score: 0.0\n",
      "Non-Traditional Classifier MSE score: 0.35758938350199343\n"
     ]
    }
   ],
   "source": [
    "#fit a model on (X, s1) and see the performance. Compare it with the two methods.\n",
    "non_trad_clf = svm.SVC(kernel='rbf', probability=True, random_state = 331).fit(np.copy(X1_train),np.copy(s1))\n",
    "name = \"Non-Traditional Classifier\"\n",
    "\n",
    "y_pred = non_trad_clf.predict(np.copy(X1_test))\n",
    "y_pred_prob = non_trad_clf.predict_proba(np.copy(X1_test))[:,1]\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spy Expectation Maximization S-EM (first dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of P: 86\n",
      "Length of M: 874\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85]\n",
      "Length of Spies: 9\n",
      "Length of Spies: 9\n",
      "Length of rest: 77\n",
      "Length of P: (77, 4)\n",
      "Length of MS: (883, 4)\n"
     ]
    }
   ],
   "source": [
    "p = np.copy(X1_train[np.where(s1==1)])\n",
    "m = np.copy(X1_train[np.where(s1==0)])\n",
    "\n",
    "\n",
    "len_p = len(p)\n",
    "print(\"Length of P:\", len_p)\n",
    "print(\"Length of M:\", len(m))\n",
    "index_population = np.arange(len_p)\n",
    "print(index_population)\n",
    "\n",
    "percent_spies = 0.1\n",
    "Spy_size = int(np.around(len_p * percent_spies))\n",
    "print(\"Length of Spies:\", Spy_size)\n",
    "Spy_index = np.random.choice(index_population, size=Spy_size, replace=False)\n",
    "Spies = p[Spy_index,:]\n",
    "print(\"Length of Spies:\", len(Spies))\n",
    "\n",
    "ms = np.concatenate((m,Spies))\n",
    "index_p = np.delete(index_population,Spy_index)\n",
    "print(\"Length of rest:\", len(index_p))\n",
    "p = np.array([p[i] for i in index_p])\n",
    "\n",
    "print(\"Length of P:\", p.shape)\n",
    "print(\"Length of MS:\", ms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(883, 4)\n",
      "(77, 4)\n",
      "0.9375\n",
      "number of iterations: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Initialize our classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "print(ms.shape)\n",
    "print(p.shape)\n",
    "\n",
    "label_ms = np.zeros(len(ms))\n",
    "label_p = np.ones(len(p))\n",
    "\n",
    "train = np.concatenate((ms,p))\n",
    "train_labels = np.concatenate((label_ms,label_p))\n",
    "\n",
    "# Train our classifier\n",
    "model = gnb.fit(train, train_labels)\n",
    "\n",
    "old = model.score(train, train_labels)\n",
    "new = old\n",
    "score_variation = 1\n",
    "tol = 1.0e-10\n",
    "max_iter = 100\n",
    "n_iter = 0\n",
    "\n",
    "while score_variation >= tol and n_iter < max_iter:\n",
    "    \n",
    "    preds = gnb.predict(ms)\n",
    "    train_labels = np.concatenate((preds,label_p))\n",
    "    \n",
    "    model = gnb.fit(train, train_labels)\n",
    "    new = model.score(train, train_labels)\n",
    "    \n",
    "    score_variation = np.absolute(new-old)\n",
    "    old = new\n",
    "    n_iter += 1\n",
    "    \n",
    "print(new)\n",
    "print(\"number of iterations:\", n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above are test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d7e9a5b7113c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpu_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0my_pred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpu_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"F1 score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "pu_classifier = SEM(tol = 1.0e-10, max_iter = 100, spy_prop = 0.1, l = 0.15,\n",
    "                    classifier = LogisticRegression(), seed=331)\n",
    "name = \"SEM\"\n",
    "\n",
    "pu_classifier.fit(np.copy(X1_train), np.copy(s1))\n",
    "\n",
    "y_pred = pu_classifier.predict(np.copy(X1_test))\n",
    "\n",
    "y_pred_prob = pu_classifier.predict_proba(np.copy(X1_test))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Logistic Regression MLR (first dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pu_classifier = ModifiedLogisticRegression(max_iter = 100, l_rate = 0.001, seed = 331)\n",
    "name = \"MLR\"\n",
    "\n",
    "pu_classifier.fit(np.copy(X1_train), np.copy(s1))\n",
    "\n",
    "pu_classifier.estimate_c()\n",
    "\n",
    "y_pred = pu_classifier.predict(np.copy(X1_test))\n",
    "\n",
    "y_pred_prob = pu_classifier.predict_proba(np.copy(X1_test))\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y1_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Dataset2_train.csv')\n",
    "X2_train= data.iloc[:, :-2].values\n",
    "y2_train = data.iloc[:, -1].values\n",
    "s2 = data.iloc[:, -2].values\n",
    "c2 = Counter(s2)[1]/Counter(y2_train)[1]\n",
    "\n",
    "data = pd.read_csv('Dataset2_test.csv')\n",
    "X2_test= data.iloc[:, :-1].values\n",
    "y2_test = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Golden Standard Classifier (second dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the dataset as fully labeled. Use this as the best case in the comparison.\n",
    "\n",
    "golden_clf = svm.SVC(kernel='rbf',probability=True,random_state = 331).fit(np.copy(X2_train),np.copy(y2_train))\n",
    "name = \"Golden Standard Classifier:\"\n",
    "\n",
    "y_best_pred = golden_clf.predict(np.copy(X2_test))\n",
    "y_best_prob = golden_clf.predict_proba(np.copy(X2_test))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y2_test, y_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Traditional Classifier (second dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a model on (X, s1) and see the performance. Compare it with the two methods.\n",
    "non_trad_clf = svm.SVC(kernel='rbf', probability=True, random_state = 331).fit(np.copy(X2_train),np.copy(s2))\n",
    "name = \"Non-Traditional Classifier\"\n",
    "\n",
    "y_pred = non_trad_clf.predict(np.copy(X2_test))\n",
    "y_pred_prob = non_trad_clf.predict_proba(np.copy(X2_test))[:,1]\n",
    "print(name,\"F1 score:\", f1_score(y2_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spy Expectation Maximization S-EM (second dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pu_classifier = SEM(tol = 1.0e-10, max_iter = 100, spy_prop = 0.1, l = 0.15, \n",
    "                    classifier = LogisticRegression(), seed=331)\n",
    "name = \"SEM\"\n",
    "\n",
    "pu_classifier.fit(np.copy(X2_train), np.copy(s2))\n",
    "\n",
    "y_pred = pu_classifier.predict(np.copy(X2_test))\n",
    "\n",
    "y_pred_prob = pu_classifier.predict_proba(np.copy(X2_test))[:,1]\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y2_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified Logistic Regression MLR (second dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pu_classifier = ModifiedLogisticRegression(max_iter = 100, l_rate = 0.001, seed = 331)\n",
    "name = \"MLR\"\n",
    "\n",
    "pu_classifier.fit(np.copy(X2_train), np.copy(s2))\n",
    "\n",
    "pu_classifier.estimate_c()\n",
    "\n",
    "y_pred = pu_classifier.predict(np.copy(X2_test))\n",
    "\n",
    "y_pred_prob = pu_classifier.predict_proba(np.copy(X2_test))\n",
    "\n",
    "print(name,\"F1 score:\", f1_score(y2_test, y_pred))\n",
    "print(name,\"MSE score:\", mse(y_best_prob, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
